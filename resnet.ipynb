{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset_name', type=str, default='COVID19_ChestXray') # required\n",
    "parser.add_argument('--model_name', type=str, default='resnet50') #required\n",
    "parser.add_argument('--result_path', type=str, default='result', help='output path')\n",
    "parser.add_argument('--data_path', type=str, default='dataset_partition', help='path for data partition')\n",
    "\n",
    "# Training\n",
    "parser.add_argument('--num_epochs', type=int, default=8)\n",
    "parser.add_argument('--batch_size', type=int, default=16)\n",
    "parser.add_argument('--lr', type=float, default=1e-5)\n",
    "parser.add_argument('-e', '--lr_decay', type=float, default=0.995,\n",
    "                    help='Learning rate decay, applied every step of the optimization')\n",
    "parser.add_argument('--seed', type=int, default=1,\n",
    "                    help='Random seed to use')\n",
    "parser.add_argument('--log_step', type=int, default=50, help='step size for prining log info')\n",
    "parser.add_argument('--save_step', type=int, default=50, help='step size for saving trained models')\n",
    "\n",
    "parser.add_argument('--flag_retrain', default=False, action='store_true', help='Re train')\n",
    "parser.add_argument('--flag_reg', default=False, action='store_true', help='Regularizer')\n",
    "parser.add_argument('--flag_plot', default=False, action='store_true', help='Plot')\n",
    "parser.add_argument('--img_size', type=int, default=256)\n",
    "\n",
    "# Model parameters\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, shutil\n",
    "import numpy as np\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms, utils\n",
    "import torchvision\n",
    "import pdb\n",
    "\n",
    "device=torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Arguments\n",
    "model_name=args.model_name + '-' + args.dataset_name\n",
    "dataset_path=os.path.join(args.data_path, args.dataset_name)\n",
    "output_path=os.path.join(args.result_path, model_name)\n",
    "\n",
    "# saved checkpoint\n",
    "model_path=os.path.join(output_path, 'snapshots')\n",
    "net_path=os.path.join(model_path, 'net.pth')\n",
    "adv_path = os.path.join(model_path, 'adv.pth')\n",
    "sample_path=os.path.join(output_path, 'samples')\n",
    "log_path=os.path.join(output_path, \"log.txt\")\n",
    "run_path = os.path.join(output_path, 'runs')\n",
    "\n",
    "params_str = 'debug'\n",
    "writer_path=os.path.join(run_path, params_str) \n",
    "\n",
    "# makedir\n",
    "def make_dir(dirname, rm=False):\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    elif rm:\n",
    "        print('rm and mkdir ', dirname)\n",
    "        shutil.rmtree(dirname)\n",
    "        os.makedirs(dirname)\n",
    "\n",
    "make_dir(args.result_path)\n",
    "make_dir(output_path)\n",
    "make_dir(model_path)\n",
    "make_dir(sample_path)\n",
    "make_dir(run_path)\n",
    "logf=open(log_path, 'w')\n",
    "make_dir(writer_path, rm=True)\n",
    "writer=SummaryWriter(comment=model_name, log_dir=writer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "importlib.reload(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging helper functions \n",
    "def log_loss(epoch, step, total_step, loss, start_time):\n",
    "    # convert\n",
    "    loss=loss.cpu().data.numpy()\n",
    "    # msg\n",
    "    message='Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, time: {:.4f}s'.format(\n",
    "        epoch, args.num_epochs, step, total_step, loss, time.time() - start_time)\n",
    "    # log out\n",
    "    logf.write(message + '\\n')\n",
    "    print(message)\n",
    "    \n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleChannel(object):\n",
    "    def __call__(self, img):\n",
    "        img = img[0,:,:].unsqueeze(0)\n",
    "        return img\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Resize(args.img_size + 24), \n",
    "                                      transforms.RandomRotation(10),\n",
    "                                      transforms.CenterCrop(args.img_size),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      SingleChannel()])\n",
    "test_transform = transforms.Compose([transforms.Resize(args.img_size + 24), \n",
    "                                     transforms.CenterCrop(args.img_size),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     SingleChannel()])\n",
    "trainset = datasets.COVID19_ChestXray_Merged_Dataset(dataset_partition=args.data_path, train=True, \n",
    "                                                    transform=train_transform)\n",
    "testset = datasets.COVID19_ChestXray_Merged_Dataset(dataset_partition=args.data_path, train=False, \n",
    "                                                    transform=test_transform)\n",
    "trainloader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    img, label = testset.__getitem__(i)\n",
    "    print(img.shape, label)\n",
    "    display(transforms.ToPILImage()(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model as mymodel\n",
    "importlib.reload(mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_using_pretrained(resnet):\n",
    "    pretrained_resnet = torchvision.models.resnet50(pretrained=True)\n",
    "    resnet.layer1.load_state_dict(pretrained_resnet.layer1.state_dict())\n",
    "    resnet.layer2.load_state_dict(pretrained_resnet.layer2.state_dict())\n",
    "    resnet.layer3.load_state_dict(pretrained_resnet.layer3.state_dict())\n",
    "    resnet.layer4.load_state_dict(pretrained_resnet.layer4.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet = mymodel.resnet50(num_classes=2)\n",
    "initialize_using_pretrained(resnet)\n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=args.lr)\n",
    "lmbda = lambda epoch: 1.0\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=[lmbda])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch, model, optimizer, dataloader, writer):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    loss_logger = AverageMeter()\n",
    "    total_step = len(dataloader.dataset)//args.batch_size\n",
    "    for idx, (images, labels) in enumerate(dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(images)\n",
    "        #pdb.set_trace()\n",
    "        loss = F.cross_entropy(pred, labels.long())\n",
    "        loss_logger.update(loss.item())\n",
    "        \n",
    "        if idx % args.log_step == 0:\n",
    "            log_loss(epoch, idx, total_step, loss, start_time)\n",
    "            start_time = time.time()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    accuracy = get_accuracy(model, dataloader)\n",
    "    print('Train Acc:', accuracy)\n",
    "    writer.add_scalar('Loss/train', loss_logger.avg, epoch)\n",
    "    writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
    "    \n",
    "def get_accuracy(model, dataloader):    \n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    i = 0\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(images)\n",
    "        #pdb.set_trace()\n",
    "        pred_labels = torch.argmax(pred, 1)\n",
    "        total += labels.size(0)\n",
    "       \n",
    "        correct += torch.sum(pred_labels == labels)\n",
    "        \n",
    "    return correct.cpu().numpy()/total\n",
    "\n",
    "def test_epoch(epoch, model, dataloader, writer):\n",
    "    model.eval()\n",
    "    loss_logger = AverageMeter()\n",
    "    \n",
    "    pred_n = None\n",
    "    correct_n = None\n",
    "    i = 0\n",
    "     \n",
    "            \n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(images)\n",
    "        loss = F.cross_entropy(pred, labels.long())\n",
    "        loss_logger.update(loss.item())\n",
    "        pred_labels = torch.argmax(pred, 1)\n",
    "        \n",
    "        if i  == 0:\n",
    "            i = i+1\n",
    "            \n",
    "            pred_n = pred_labels\n",
    "            correct_n = labels\n",
    "            \n",
    "        else:\n",
    "            pred_n = torch.cat((pred_n,pred_labels),0)\n",
    "            correct_n = torch.cat((correct_n,labels),0)\n",
    "            \n",
    "        \n",
    "    accuracy = get_accuracy(model, dataloader)\n",
    "    print('Test Acc:', accuracy)\n",
    "    writer.add_scalar('Loss/test', loss_logger.avg, epoch)\n",
    "    writer.add_scalar('Accuracy/test', accuracy, epoch)\n",
    "    \n",
    "    confusion_vector = pred_n/correct_n\n",
    "    true_positives = torch.sum(confusion_vector == 1).item()\n",
    "    false_positives = torch.sum(confusion_vector == float('inf')).item()\n",
    "    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n",
    "    false_negatives = torch.sum(confusion_vector == 0).item()\n",
    "\n",
    "#     print(\"CV\", true_positives, false_positives, true_negatives, false_negatives)\n",
    "    print(\"Precsion \", true_positives/(true_positives+false_positives),\"Recall \", true_positives/(true_positives+false_negatives))\n",
    "     \n",
    "        \n",
    "def train(model, optimizer, scheduler, trainloader, testloader, writer):\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_epoch(epoch, model, optimizer, trainloader, writer)\n",
    "        test_epoch(epoch, model, testloader, writer)\n",
    "        scheduler.step()\n",
    "    print('Saving the model')\n",
    "    torch.save(model.state_dict(), net_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(resnet, optimizer, scheduler, trainloader, testloader, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights\n",
    "We can visualize on what the model focusses on from this data using CAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 16,16\n",
    "import matplotlib.cm as cm\n",
    "import cam\n",
    "importlib.reload(cam)\n",
    "from gradcam.grad_cam import (\n",
    "    BackPropagation,\n",
    "    Deconvnet,\n",
    "    GradCAM,\n",
    "    GuidedBackPropagation,\n",
    "    occlusion_sensitivity,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model from the saved snapshot\n",
    "model = mymodel.resnet50(num_classes=2).to(device)\n",
    "model.load_state_dict(torch.load(net_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad-CAM\n",
    "Based on https://github.com/kazuto1011/grad-cam-pytorch#demo-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_act_map(gradient):\n",
    "    gradient = gradient.cpu()\n",
    "    gradient -= gradient.min()\n",
    "    gradient /= gradient.max()\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_guided_gradcam(model, dataloader):\n",
    "    rcParams['figure.figsize'] = 16,16\n",
    "    def show_cams(image, regions, gradients):\n",
    "        image = image.cpu()\n",
    "        act_map = get_act_map(torch.mul(regions, gradients))\n",
    "        gcam_map = cam.apply_colormap_on_image(to_image(image), np.uint8(regions.squeeze().cpu().numpy()*255))\n",
    "        fig, ax = plt.subplots(1,3)\n",
    "        ax[0].imshow(to_image(image), cmap='gray')\n",
    "        ax[2].imshow(to_image(act_map), cmap='gray')\n",
    "        ax[1].imshow(gcam_map)\n",
    "        plt.show()\n",
    "    \n",
    "    model.eval()\n",
    "    to_image = transforms.ToPILImage()\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred_labels = torch.argmax(pred, 1)\n",
    "        \n",
    "        # For each covid-19 positive chest-xray we try to see the regions used according to gradcam\n",
    "        gcam = GradCAM(model=model)\n",
    "        _ = gcam.forward(images)\n",
    "        gbp = GuidedBackPropagation(model=model)\n",
    "        _ = gbp.forward(images)\n",
    "        ids = torch.argmax(pred, 1).unsqueeze(1)\n",
    "        # Gradient\n",
    "        gbp.backward(ids=ids)\n",
    "        gradients = gbp.generate()\n",
    "\n",
    "        # Grad-CAM\n",
    "        gcam.backward(ids=ids)\n",
    "        regions = gcam.generate(target_layer=\"layer4\")  # For resent the target layer is layer4\n",
    "\n",
    "        # Show the activation maps\n",
    "        for i in range(len(images)):\n",
    "            if labels[i] == 1 and pred_labels[i] == 1:\n",
    "                print('COVID-19')\n",
    "            elif labels[i] == 0 and pred_labels[i] == 0:\n",
    "                print('Normal')\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            show_cams(images[i], regions[i], gradients[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_guided_gradcam(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_image = transforms.ToPILImage()\n",
    "rcParams['figure.figsize'] = 10,10\n",
    "for i in range(len(testset)):\n",
    "    img, label = testset.__getitem__(i)\n",
    "    if label == 1:\n",
    "        print('COVID-19')\n",
    "    else:\n",
    "        continue\n",
    "        print('Normal')\n",
    "    cam_img = cam.get_cam_images(model, 'layer4', img.to(device).unsqueeze(0), corona_idx=label)[0]\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[0].imshow(to_image(img), cmap='gray')\n",
    "    ax[1].imshow(cam_img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
